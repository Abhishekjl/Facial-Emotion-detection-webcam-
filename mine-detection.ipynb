{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-01T15:32:35.940849Z","iopub.execute_input":"2021-11-01T15:32:35.941274Z","iopub.status.idle":"2021-11-01T15:32:35.975485Z","shell.execute_reply.started":"2021-11-01T15:32:35.941189Z","shell.execute_reply":"2021-11-01T15:32:35.9747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport scipy\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:32:09.021619Z","iopub.execute_input":"2021-11-01T17:32:09.022Z","iopub.status.idle":"2021-11-01T17:32:09.129794Z","shell.execute_reply.started":"2021-11-01T17:32:09.021964Z","shell.execute_reply":"2021-11-01T17:32:09.128739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/facial-expression-recognitionferchallenge/fer2013/fer2013/fer2013.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:32:09.581246Z","iopub.execute_input":"2021-11-01T17:32:09.581651Z","iopub.status.idle":"2021-11-01T17:32:15.055182Z","shell.execute_reply.started":"2021-11-01T17:32:09.581612Z","shell.execute_reply":"2021-11-01T17:32:15.054218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:32:15.056847Z","iopub.execute_input":"2021-11-01T17:32:15.057158Z","iopub.status.idle":"2021-11-01T17:32:15.089096Z","shell.execute_reply.started":"2021-11-01T17:32:15.057128Z","shell.execute_reply":"2021-11-01T17:32:15.087517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Assigning Names to Emotions in labels\n\nnum_classes = 7\nwidth = 48\nheight = 48\nemotion_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\nclasses=np.array((\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"))\ndf.Usage.value_counts() ","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:32:15.091376Z","iopub.execute_input":"2021-11-01T17:32:15.091823Z","iopub.status.idle":"2021-11-01T17:32:15.110516Z","shell.execute_reply.started":"2021-11-01T17:32:15.091779Z","shell.execute_reply":"2021-11-01T17:32:15.109196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k = np.array(list(map(int,df.iloc[0,1].split(\" \"))),dtype='uint8').reshape((48,48))","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:32:15.112743Z","iopub.execute_input":"2021-11-01T17:32:15.113196Z","iopub.status.idle":"2021-11-01T17:32:15.122023Z","shell.execute_reply.started":"2021-11-01T17:32:15.113153Z","shell.execute_reply":"2021-11-01T17:32:15.120582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"k.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:32:15.124052Z","iopub.execute_input":"2021-11-01T17:32:15.124583Z","iopub.status.idle":"2021-11-01T17:32:15.13592Z","shell.execute_reply.started":"2021-11-01T17:32:15.124542Z","shell.execute_reply":"2021-11-01T17:32:15.134527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = []\ny_train = []\nX_test = []\ny_test = []\nfor index, row in df.iterrows():\n    k = row['pixels'].split(\" \")\n    if row['Usage'] == 'Training':\n        X_train.append(np.array(k))\n        y_train.append(row['emotion'])\n    elif row['Usage'] == 'PublicTest':\n        X_test.append(np.array(k))\n        y_test.append(row['emotion'])","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:32:15.137755Z","iopub.execute_input":"2021-11-01T17:32:15.138284Z","iopub.status.idle":"2021-11-01T17:32:43.677382Z","shell.execute_reply.started":"2021-11-01T17:32:15.138227Z","shell.execute_reply":"2021-11-01T17:32:43.676112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train[0]","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:32:43.67932Z","iopub.execute_input":"2021-11-01T17:32:43.67974Z","iopub.status.idle":"2021-11-01T17:32:43.687313Z","shell.execute_reply.started":"2021-11-01T17:32:43.679708Z","shell.execute_reply":"2021-11-01T17:32:43.686296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(np.array(X_train[0], dtype = 'uint8').reshape(48,48,1), cmap = 'gray')","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:32:43.68924Z","iopub.execute_input":"2021-11-01T17:32:43.689844Z","iopub.status.idle":"2021-11-01T17:32:43.887386Z","shell.execute_reply.started":"2021-11-01T17:32:43.689803Z","shell.execute_reply":"2021-11-01T17:32:43.886358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = np.array(X_train, dtype = 'uint8')\ny_train = np.array(y_train, dtype = 'uint8')\nX_test = np.array(X_test, dtype = 'uint8')\ny_test = np.array(y_test, dtype = 'uint8')","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:32:43.888929Z","iopub.execute_input":"2021-11-01T17:32:43.889537Z","iopub.status.idle":"2021-11-01T17:33:30.057631Z","shell.execute_reply.started":"2021-11-01T17:32:43.889481Z","shell.execute_reply":"2021-11-01T17:33:30.05602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\nX_test = X_test.reshape(X_test.shape[0], 48, 48, 1)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:33:30.059647Z","iopub.execute_input":"2021-11-01T17:33:30.060256Z","iopub.status.idle":"2021-11-01T17:33:30.073933Z","shell.execute_reply.started":"2021-11-01T17:33:30.060204Z","shell.execute_reply":"2021-11-01T17:33:30.072879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:33:30.075761Z","iopub.execute_input":"2021-11-01T17:33:30.076287Z","iopub.status.idle":"2021-11-01T17:33:30.087422Z","shell.execute_reply.started":"2021-11-01T17:33:30.076241Z","shell.execute_reply":"2021-11-01T17:33:30.08654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras.utils import to_categorical\ny_train= to_categorical(y_train, num_classes=7)\ny_test = to_categorical(y_test, num_classes=7)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:33:30.091393Z","iopub.execute_input":"2021-11-01T17:33:30.092036Z","iopub.status.idle":"2021-11-01T17:33:34.987728Z","shell.execute_reply.started":"2021-11-01T17:33:30.091985Z","shell.execute_reply":"2021-11-01T17:33:34.986772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### some image augumentation","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator \ndatagen = ImageDataGenerator( \n    rescale=1./255,\n    rotation_range = 10,\n    horizontal_flip = True,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    fill_mode = 'nearest')\n\ntestgen = ImageDataGenerator( \n    rescale=1./255\n    )\ndatagen.fit(X_train)\nbatch_size = 64","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:33:34.989689Z","iopub.execute_input":"2021-11-01T17:33:34.990086Z","iopub.status.idle":"2021-11-01T17:33:35.123223Z","shell.execute_reply.started":"2021-11-01T17:33:34.990044Z","shell.execute_reply":"2021-11-01T17:33:35.121977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_flow = datagen.flow(X_train, y_train, batch_size=batch_size) \ntest_flow = testgen.flow(X_test, y_test, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:33:35.12491Z","iopub.execute_input":"2021-11-01T17:33:35.125346Z","iopub.status.idle":"2021-11-01T17:33:35.195016Z","shell.execute_reply.started":"2021-11-01T17:33:35.125303Z","shell.execute_reply":"2021-11-01T17:33:35.193983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for X_batch, y_batch in datagen.flow(X_train, y_train, batch_size=9):\n    for i in range(0, 9): \n        plt.axis('off') \n        plt.subplot(330 + 1 + i) \n        plt.imshow(X_batch[i].reshape(48, 48), cmap=plt.get_cmap('gray'))\n    plt.axis('off') \n    plt.show() \n    break","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:33:35.196618Z","iopub.execute_input":"2021-11-01T17:33:35.197034Z","iopub.status.idle":"2021-11-01T17:33:35.680308Z","shell.execute_reply.started":"2021-11-01T17:33:35.196979Z","shell.execute_reply":"2021-11-01T17:33:35.679319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Creating model for training ","metadata":{}},{"cell_type":"code","source":"from keras.layers import ZeroPadding2D,Convolution2D,MaxPooling2D,Flatten,Dense,Dropout\nfrom keras.models import Sequential","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:33:35.681797Z","iopub.execute_input":"2021-11-01T17:33:35.682372Z","iopub.status.idle":"2021-11-01T17:33:35.688596Z","shell.execute_reply.started":"2021-11-01T17:33:35.682328Z","shell.execute_reply":"2021-11-01T17:33:35.687504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import plot_model\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.optimizers import Adam, SGD\nfrom keras.regularizers import l1, l2\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:33:35.690409Z","iopub.execute_input":"2021-11-01T17:33:35.691157Z","iopub.status.idle":"2021-11-01T17:33:36.563502Z","shell.execute_reply.started":"2021-11-01T17:33:35.691112Z","shell.execute_reply":"2021-11-01T17:33:36.562429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def FER_Model(input_shape=(48,48,1)):\n    # first input model\n    visible = Input(shape=input_shape, name='input')\n    num_classes = 7\n    #the 1-st block\n    conv1_1 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_1')(visible)\n    conv1_1 = BatchNormalization()(conv1_1)\n    conv1_2 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_2')(conv1_1)\n    conv1_2 = BatchNormalization()(conv1_2)\n    pool1_1 = MaxPooling2D(pool_size=(2,2), name = 'pool1_1')(conv1_2)\n    drop1_1 = Dropout(0.3, name = 'drop1_1')(pool1_1)\n\n    #the 2-nd block\n    conv2_1 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_1')(drop1_1)\n    conv2_1 = BatchNormalization()(conv2_1)\n    conv2_2 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_2')(conv2_1)\n    conv2_2 = BatchNormalization()(conv2_2)\n    conv2_3 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_3')(conv2_2)\n    conv2_2 = BatchNormalization()(conv2_3)\n    pool2_1 = MaxPooling2D(pool_size=(2,2), name = 'pool2_1')(conv2_3)\n    drop2_1 = Dropout(0.3, name = 'drop2_1')(pool2_1)\n\n     #the 3-rd block\n    conv3_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_1')(drop2_1)\n    conv3_1 = BatchNormalization()(conv3_1)\n    conv3_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_2')(conv3_1)\n    conv3_2 = BatchNormalization()(conv3_2)\n    conv3_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_3')(conv3_2)\n    conv3_3 = BatchNormalization()(conv3_3)\n    conv3_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_4')(conv3_3)\n    conv3_4 = BatchNormalization()(conv3_4)\n    pool3_1 = MaxPooling2D(pool_size=(2,2), name = 'pool3_1')(conv3_4)\n    drop3_1 = Dropout(0.3, name = 'drop3_1')(pool3_1)\n\n    #the 4-th block\n    conv4_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_1')(drop3_1)\n    conv4_1 = BatchNormalization()(conv4_1)\n    conv4_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_2')(conv4_1)\n    conv4_2 = BatchNormalization()(conv4_2)\n    conv4_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_3')(conv4_2)\n    conv4_3 = BatchNormalization()(conv4_3)\n    conv4_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_4')(conv4_3)\n    conv4_4 = BatchNormalization()(conv4_4)\n    pool4_1 = MaxPooling2D(pool_size=(2,2), name = 'pool4_1')(conv4_4)\n    drop4_1 = Dropout(0.3, name = 'drop4_1')(pool4_1)\n    \n    #the 5-th block\n    conv5_1 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_1')(drop4_1)\n    conv5_1 = BatchNormalization()(conv5_1)\n    conv5_2 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_2')(conv5_1)\n    conv5_2 = BatchNormalization()(conv5_2)\n    conv5_3 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_3')(conv5_2)\n    conv5_3 = BatchNormalization()(conv5_3)\n    conv5_4 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_4')(conv5_3)\n    conv5_3 = BatchNormalization()(conv5_3)\n    pool5_1 = MaxPooling2D(pool_size=(2,2), name = 'pool5_1')(conv5_4)\n    drop5_1 = Dropout(0.3, name = 'drop5_1')(pool5_1)\n\n    #Flatten and output\n    flatten = Flatten(name = 'flatten')(drop5_1)\n    ouput = Dense(num_classes, activation='softmax', name = 'output')(flatten)\n\n    # create model \n    model = Model(inputs =visible, outputs = ouput)\n    # summary layers\n    print(model.summary())\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:33:36.568669Z","iopub.execute_input":"2021-11-01T17:33:36.57121Z","iopub.status.idle":"2021-11-01T17:33:36.608312Z","shell.execute_reply.started":"2021-11-01T17:33:36.571163Z","shell.execute_reply":"2021-11-01T17:33:36.607241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = FER_Model()\nopt = Adam(lr=0.0001, decay=1e-6)\nmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:33:36.613493Z","iopub.execute_input":"2021-11-01T17:33:36.61628Z","iopub.status.idle":"2021-11-01T17:33:39.04201Z","shell.execute_reply.started":"2021-11-01T17:33:36.616235Z","shell.execute_reply":"2021-11-01T17:33:39.041065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\nfilepath=\"weights_min_loss.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [checkpoint]","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:33:39.044254Z","iopub.execute_input":"2021-11-01T17:33:39.04469Z","iopub.status.idle":"2021-11-01T17:33:39.050518Z","shell.execute_reply.started":"2021-11-01T17:33:39.044648Z","shell.execute_reply":"2021-11-01T17:33:39.04942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 100  \nhistory = model.fit_generator(train_flow, \n                    steps_per_epoch=len(X_train) / batch_size, \n                    epochs=num_epochs,  \n                    verbose=2,  \n                    callbacks=callbacks_list,\n                    validation_data=test_flow,  \n                    validation_steps=len(X_test) / batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-11-01T17:33:39.052225Z","iopub.execute_input":"2021-11-01T17:33:39.052736Z","iopub.status.idle":"2021-11-01T18:03:44.376136Z","shell.execute_reply.started":"2021-11-01T17:33:39.05265Z","shell.execute_reply":"2021-11-01T18:03:44.375198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### for testing","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\n\ntrain_loss=history.history['loss']\nval_loss=history.history['val_loss']\ntrain_acc=history.history['accuracy']\nval_acc=history.history['val_accuracy']\n\nepochs = range(len(train_acc))\n\nplt.plot(epochs,train_loss,'r', label='train_loss')\nplt.plot(epochs,val_loss,'b', label='val_loss')\nplt.title('train_loss vs val_loss')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs,train_acc,'r', label='train_acc')\nplt.plot(epochs,val_acc,'b', label='val_acc')\nplt.title('train_acc vs val_acc')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend()\nplt.figure()","metadata":{"execution":{"iopub.status.busy":"2021-11-01T18:03:44.37782Z","iopub.execute_input":"2021-11-01T18:03:44.378161Z","iopub.status.idle":"2021-11-01T18:03:44.760521Z","shell.execute_reply.started":"2021-11-01T18:03:44.378127Z","shell.execute_reply":"2021-11-01T18:03:44.759582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('../working/Fer2013.h5')\n","metadata":{"execution":{"iopub.status.busy":"2021-08-13T16:37:00.590203Z","iopub.execute_input":"2021-08-13T16:37:00.590609Z","iopub.status.idle":"2021-08-13T16:37:00.947277Z","shell.execute_reply.started":"2021-08-13T16:37:00.590574Z","shell.execute_reply":"2021-08-13T16:37:00.946354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = model.evaluate(X_test/255., y_test) \nprint(\"Test Loss \" + str(loss[0]))\nprint(\"Test Acc: \" + str(loss[1]))","metadata":{"execution":{"iopub.status.busy":"2021-11-01T18:28:52.364131Z","iopub.execute_input":"2021-11-01T18:28:52.364488Z","iopub.status.idle":"2021-11-01T18:28:52.433146Z","shell.execute_reply.started":"2021-11-01T18:28:52.364393Z","shell.execute_reply":"2021-11-01T18:28:52.431702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(y_test, y_pred, classes,\n                          normalize=False,\n                          title='Unnormalized confusion matrix',\n                          cmap=plt.cm.Blues):\n    cm = confusion_matrix(y_test, y_pred)\n    \n    if normalize:\n        cm = np.round(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], 2)\n        \n    np.set_printoptions(precision=2)\n        \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.min() + (cm.max() - cm.min()) / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True expression')\n    plt.xlabel('Predicted expression')\n    plt.show()\ny_pred_ = model.predict(X_test/255., verbose=1)\ny_pred = np.argmax(y_pred_, axis=1)\nt_te = np.argmax(y_test, axis=1)\nfig = plot_confusion_matrix(y_test=t_te, y_pred=y_pred,\n                      classes=classes,\n                      normalize=True,\n                      cmap=plt.cm.Greys,   title='Average accuracy: ' + str(np.sum(y_pred == t_te)/len(t_te)) + '\\n')","metadata":{"execution":{"iopub.status.busy":"2021-11-01T18:28:52.435119Z","iopub.status.idle":"2021-11-01T18:28:52.435568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_json = model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\nmodel.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")","metadata":{"execution":{"iopub.status.busy":"2021-11-01T18:28:52.43841Z","iopub.status.idle":"2021-11-01T18:28:52.438796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}